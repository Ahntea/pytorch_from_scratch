{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYabtg5iFp09mU2a2b+GjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahntea/pytorch_from_scratch/blob/main/age_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20oYsK8UbGjr",
        "outputId": "cddf8b2d-a00d-4548-f0e7-5160ae583e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "!apt-get -qq -y install fonts-nanum > /dev/null\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "fm._rebuild()\n",
        "# 단계 3: 한글 폰트 설정\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 마이너스 표시 문제\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\t\n",
        "# 한글 폰트 설정\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf'\n",
        "font_name = fm.FontProperties(fname=path, size=18).get_name()\n",
        "plt.rc('font', family=font_name)\n",
        "fm._rebuild()\n",
        "\n",
        "filename = \"/content/drive/MyDrive/thumbnail_list.txt\"\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 변환\n",
        "name_list = []\n",
        "with open(filename) as f:\n",
        "    for line in f:\n",
        "        name_list.append(unicodedata.normalize(\"NFC\", line.strip()))"
      ],
      "metadata": {
        "id": "u5hCE4FAbTZV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# thumbnail dataframe 생성\n",
        "thumbnail = pd.DataFrame(name_list)\n",
        "thumbnail[\"image\"]= thumbnail[0].str.replace('_PMT.jpg', '.jpg')\n",
        "thumbnail.rename(columns = {0:\"filename\"}, inplace = True)"
      ],
      "metadata": {
        "id": "nFMByd2sbUAT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image 생성날짜 dataframe 로드 및 merge\n",
        "imt = pd.read_csv(\"/content/drive/MyDrive/csv_image_table_1015.csv\")\n",
        "\n",
        "merged = pd.merge(thumbnail, imt, how=\"left\", on = \"image\" )\n",
        "merged['gen_date'] = pd.to_datetime(merged[['year','month','day']], format='%Y%m%d')\n",
        "merged[\"birth_date\"] = merged[\"image\"].str.split('_', expand=True)[2]\n",
        "merged[\"birth_date\"] = merged[\"birth_date\"].astype(\"datetime64[ns]\")\n",
        "merged[\"age\"] = (merged[\"gen_date\"] - merged[\"birth_date\"]) / np.timedelta64(1, 'Y')\n",
        "merged[\"age\"].fillna(35, inplace=True)\n",
        "merged[\"age\"] = merged[\"age\"].astype(int)\n",
        "merged.loc[merged[\"age\"]==119, \"age\"] = 19\n",
        "merged[\"category\"] = merged[\"image\"].str.split('_', expand=True)[4]\n",
        "d_ages = merged[['filename','age']].set_index('filename').T.to_dict('list')"
      ],
      "metadata": {
        "id": "lJ2UziTebVNk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 데이터 셋 생성\n",
        "import os\n",
        "\n",
        "dir_list = []\n",
        "jpg_list = []\n",
        "def search(dirname):\n",
        "    filenames = os.listdir(dirname)\n",
        "    for filename in filenames:\n",
        "        full_filename = os.path.join(dirname, filename)\n",
        "        ext = os.path.splitext(full_filename)[-1]\n",
        "        if ext != '.py': \n",
        "            dir_list.append(full_filename)\n",
        "\n",
        "def search2(dirname):\n",
        "    filenames = os.listdir(dirname)\n",
        "    for filename in filenames:\n",
        "        full_filename = os.path.join(dirname, filename)\n",
        "        ext = os.path.splitext(full_filename)[-1]\n",
        "        if ext == '.jpg': \n",
        "            jpg_list.append(full_filename)\n",
        "            \n",
        " # 폴더 경로\n",
        "path = '/content/drive/MyDrive/thumbnail'\n",
        "search(path)\n",
        "for dl in dir_list:\n",
        "  search2(dl)"
      ],
      "metadata": {
        "id": "jipjVXv9nwWm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# os.chdir(path) # 해당 폴더로 이동\n",
        "# files = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
        "x_train = np.empty((0,28800))\n",
        "train_names = []\n",
        "i = 0\n",
        "for f in jpg_list[:1000]:\n",
        "  train_names.append(unicodedata.normalize(\"NFC\", f.split('/')[6]))\n",
        "  temp = np.array(Image.open(f))\n",
        "  # print(f)\n",
        "  if temp.shape == (96, 100, 3):\n",
        "    x_train = np.append(x_train, temp.reshape(1,28800),axis=0)\n",
        "    # print(x_train.shape)\n",
        "x_train = x_train.astype(np.float32)\n",
        "\n",
        "y_train = np.array([])\n",
        "for n in train_names:\n",
        "  # print(merged.loc[merged[\"filename\"]==n, \"age\"])\n",
        "  y_train = np.append(y_train, merged.loc[merged[\"filename\"]==n, \"age\"].to_numpy())\n",
        "y_train = y_train.astype(np.float32)"
      ],
      "metadata": {
        "id": "tCJhMU06bVUQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터 셋 생성\n",
        "path = '/content/drive/MyDrive/test'\n",
        "os.chdir(path) # 해당 폴더로 이동\n",
        "files = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
        "x_valid = np.empty((0,28800))\n",
        "valid_names = []\n",
        "for f in files:\n",
        "  valid_names.append(unicodedata.normalize(\"NFC\", f))\n",
        "  temp = np.array(Image.open(f))\n",
        "  if temp.shape == (96, 100, 3):\n",
        "    # print(temp.reshape(28800))\n",
        "    x_valid = np.append(x_valid, temp.reshape(1,28800), axis=0)\n",
        "x_valid = x_valid.astype(np.float32)\n",
        "\n",
        "y_valid = np.array([])\n",
        "for n in valid_names:\n",
        "  # print(merged.loc[merged[\"filename\"]==n, \"age\"])\n",
        "  y_valid = np.append(y_valid, merged.loc[merged[\"filename\"]==n, \"age\"].to_numpy())\n",
        "y_valid = y_valid.astype(np.float32)"
      ],
      "metadata": {
        "id": "rcEjdZZkbVX3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 선언\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train/255, y_train, x_valid/255, y_valid)\n",
        ")\n",
        "print(x_train.shape)\n",
        "n, c = x_train.shape\n",
        "print(x_train, y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.min(), y_train.max())"
      ],
      "metadata": {
        "id": "9fQMbMDDbVbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997221db-40b3-4fb2-faa7-d2d19a262afc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([979, 28800])\n",
            "tensor([[0.1529, 0.2039, 0.4706,  ..., 0.0275, 0.0235, 0.0471],\n",
            "        [0.0902, 0.1255, 0.3412,  ..., 0.0235, 0.0275, 0.0353],\n",
            "        [0.1843, 0.2314, 0.5137,  ..., 0.1294, 0.1725, 0.3843],\n",
            "        ...,\n",
            "        [0.1020, 0.1647, 0.4078,  ..., 0.0980, 0.1608, 0.3647],\n",
            "        [0.1059, 0.1608, 0.4000,  ..., 0.7216, 0.6471, 0.3373],\n",
            "        [0.1059, 0.1804, 0.4392,  ..., 0.1020, 0.1608, 0.3765]]) tensor([35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
            "        35., 35., 35., 35., 35., 35., 35., 31., 31., 31., 26., 26., 26., 26.,\n",
            "        26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26.,\n",
            "        26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26., 26.,\n",
            "        26., 26., 26., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25.,\n",
            "        25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25.,\n",
            "        25., 25., 25., 25., 25., 25., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
            "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 44., 44.,\n",
            "        44., 44., 44., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41.,\n",
            "        41., 41., 41., 41., 41., 41., 41., 35., 35., 35., 35., 35., 35., 35.,\n",
            "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 30., 30., 30.,\n",
            "        30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30.,\n",
            "        51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51.,\n",
            "        51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 51., 32., 32.,\n",
            "        32., 31., 31., 31., 31., 31., 31., 31., 31., 31., 31., 31., 31., 27.,\n",
            "        27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
            "        27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 24., 24.,\n",
            "        24., 24., 24., 66., 66., 66., 66., 66., 66., 66., 66., 66., 66., 66.,\n",
            "        66., 66., 66., 66., 66., 66., 66., 66., 66., 66., 66., 62., 62., 62.,\n",
            "        62., 62., 62., 62., 62., 62., 62., 62., 62., 62., 62., 62., 62., 62.,\n",
            "        62., 62., 62., 62., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
            "        32., 32., 32., 32., 32., 32., 32., 32., 32., 33., 32., 33., 32., 33.,\n",
            "        33., 33., 33., 32., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
            "        33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
            "        33., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
            "        32., 33., 33., 33., 33., 33., 33., 42., 42., 42., 42., 42., 42., 34.,\n",
            "        34., 34., 34., 34., 34., 34., 34., 34., 34., 26., 26., 26., 26., 26.,\n",
            "        26., 26., 26., 26., 26., 55., 55., 55., 55., 55., 55., 55., 55., 55.,\n",
            "        55., 55., 55., 55., 55., 55., 55., 53., 53., 53., 53., 53., 53., 53.,\n",
            "        53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53.,\n",
            "        53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53., 53.,\n",
            "        53., 53., 53., 53., 54., 54., 54., 54., 53., 54., 54., 54., 54., 54.,\n",
            "        54., 54., 32., 32., 32., 32., 32., 28., 28., 28., 28., 28., 28., 28.,\n",
            "        28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 28., 21.,\n",
            "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
            "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 22., 22.,\n",
            "        22., 22., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25.,\n",
            "        25., 25., 25., 25., 25., 25., 25., 25., 25., 18., 18., 18., 18., 18.,\n",
            "        18., 18., 23., 23., 23., 23., 23., 23., 23., 23., 23., 24., 24., 24.,\n",
            "        24., 24., 24., 24., 23., 24., 24., 24., 22., 22., 22., 22., 22., 22.,\n",
            "        22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22.,\n",
            "        22., 23., 22., 22., 23., 23., 23., 23., 37., 37., 37., 37., 37., 37.,\n",
            "        37., 37., 37., 37., 37., 27., 27., 27., 34., 34., 34., 34., 33., 33.,\n",
            "        33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
            "        33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
            "        33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n",
            "        33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 34., 34., 34., 34.,\n",
            "        34., 33., 34., 34., 34., 34., 34., 34., 34., 34., 34., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 25., 25., 25., 25., 25., 25., 25., 25., 25., 25.,\n",
            "        25., 25., 25., 27., 27., 27., 27., 27., 27., 27., 27., 30., 30., 30.,\n",
            "        30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30.,\n",
            "        30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30.,\n",
            "        30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30., 30.,\n",
            "        30., 38., 38., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
            "        38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38.,\n",
            "        38., 38., 21., 21., 21., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 29., 29.,\n",
            "        29., 29., 29., 29., 29., 29., 29., 29., 29., 29., 27., 27., 27., 27.,\n",
            "        27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
            "        27., 27., 27., 28., 28., 28., 28., 28., 27., 27., 27., 27., 27., 27.,\n",
            "        22., 22., 22., 22., 22., 22., 22., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
            "        40., 40., 40., 40., 40., 34., 34., 34., 34., 34., 34., 44., 44., 44.,\n",
            "        44., 44., 44., 44., 44., 44., 44., 44., 44., 44., 45., 44., 45., 45.,\n",
            "        45., 44., 45., 44., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45.,\n",
            "        45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45., 45.,\n",
            "        44., 44., 44., 44., 44., 44.])\n",
            "torch.Size([979, 28800])\n",
            "tensor(18.) tensor(66.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(28800, 1) / math.sqrt(28800)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "model = nn.Linear(28800,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "id": "XuR0XbSqbVfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679fa720-8f07-4099-a5f1-f4d817cafb61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([1000])) that is different to the input size (torch.Size([979, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 1377.721191\n",
            "Epoch  100/2000 Cost: 152.823837\n",
            "Epoch  200/2000 Cost: 143.820984\n",
            "Epoch  300/2000 Cost: 137.546127\n",
            "Epoch  400/2000 Cost: 133.127609\n",
            "Epoch  500/2000 Cost: 129.984360\n",
            "Epoch  600/2000 Cost: 127.722168\n",
            "Epoch  700/2000 Cost: 126.072418\n",
            "Epoch  800/2000 Cost: 124.851410\n",
            "Epoch  900/2000 Cost: 123.932762\n",
            "Epoch 1000/2000 Cost: 123.229233\n",
            "Epoch 1100/2000 Cost: 122.680099\n",
            "Epoch 1200/2000 Cost: 122.242973\n",
            "Epoch 1300/2000 Cost: 121.887993\n",
            "Epoch 1400/2000 Cost: 121.593994\n",
            "Epoch 1500/2000 Cost: 121.345818\n",
            "Epoch 1600/2000 Cost: 121.132576\n",
            "Epoch 1700/2000 Cost: 120.946350\n",
            "Epoch 1800/2000 Cost: 120.781349\n",
            "Epoch 1900/2000 Cost: 120.633217\n",
            "Epoch 2000/2000 Cost: 120.498756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = []"
      ],
      "metadata": {
        "id": "yTYEaZ2h0uyb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(x_valid)):\n",
        "  pred_y.append(model(x_valid[i]).detach().item())"
      ],
      "metadata": {
        "id": "9HAEjscibVlw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_valid), len(pred_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M8Y3mWkunZM",
        "outputId": "c6614eb6-c1c9-4167-c8e8-d930049a729b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86 153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_y[:86], y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0sXebx2vt5hU",
        "outputId": "d5f45edc-1d54-4e66-aa80-8b6e9003389b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fed4997b7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
        "    def __init__(self): #\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(28800, 1) # 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "3FeP91aBbVpy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "HHOpxPFEbVtZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ckkS51lObVxF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MWdfBz45bV05"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ifGIaH5sbV4c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "suUH-Ci8bV7t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfoSLJEibV_f"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}